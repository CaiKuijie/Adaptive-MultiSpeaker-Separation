{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get your datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are on PC\n",
      "Data with 40 male and female speakers\n"
     ]
    }
   ],
   "source": [
    "from data.dataset import H5PY_RW\n",
    "from data.data_tools import read_metadata, males_keys, females_keys\n",
    "\n",
    "H5_dic = read_metadata()\n",
    "chunk_size = 512*10\n",
    "\n",
    "males = H5PY_RW('test_raw_16k.h5py', subset = males_keys(H5_dic)).set_chunk(chunk_size).shuffle()\n",
    "fem = H5PY_RW('test_raw_16k.h5py', subset = females_keys(H5_dic)).set_chunk(chunk_size).shuffle()\n",
    "print 'Data with', len(H5_dic), 'male and female speakers'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import Mixer\n",
    "\n",
    "mixed_data = Mixer([males, fem], with_mask=False, with_inputs=True)\n",
    "\n",
    "# Training set selection\n",
    "mixed_data.select_split(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model pretrained loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "max_pool = 128\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "\n",
    "config_model = {}\n",
    "config_model[\"type\"] = \"DPCL_train_front\"\n",
    "\n",
    "config_model[\"batch_size\"] = batch_size\n",
    "config_model[\"chunk_size\"] = chunk_size\n",
    "\n",
    "config_model[\"N\"] = N\n",
    "config_model[\"maxpool\"] = max_pool\n",
    "config_model[\"window\"] = 1024\n",
    "\n",
    "config_model[\"smooth_size\"] = 20\n",
    "\n",
    "config_model[\"alpha\"] = learning_rate\n",
    "config_model[\"reg\"] = 1e-4\n",
    "config_model[\"beta\"] = 0.1\n",
    "config_model[\"rho\"] = 0.01\n",
    "\n",
    "idd = ''.join('-{}={}-'.format(key, val) for key, val in sorted(config_model.items()))\n",
    "config_model[\"type\"] = \"DPCL_finetuning\"\n",
    "config_model[\"batch_size\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID : AdaptiveNet-icy-mountain-2296\n",
      "Tensor(\"separate/network/Gather:0\", shape=(?, 2, ?), dtype=float32)\n",
      "Tensor(\"separate/Reshape_5:0\", shape=(?, ?, 256, 1), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /home/anthony/das/log/DPCL_train_front/AdaptiveNet-wispy-forest-8617-N=256--alpha=0.001--batch_size=8--beta=0.1--chunk_size=5120--maxpool=128--reg=0.0001--rho=0.01--smooth_size=20--type=DPCL_train_front--window=1024-/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "from models.adapt import Adapt\n",
    "import config\n",
    "full_id = 'wispy-forest-8617'+idd\n",
    "\n",
    "folder='DPCL_fine_tuning'\n",
    "model = Adapt(config_model=config_model,pretraining= False, folder=folder)\n",
    "path = os.path.join(config.workdir, 'log', 'DPCL_train_front')\n",
    "\n",
    "from models.dpcl import DPCL\n",
    "\n",
    "model.connect_front_back_to_separator(DPCL)\n",
    "\n",
    "with model.graph.as_default():\n",
    "    model.create_saver()\n",
    "    model.restore_model(path, full_id)\n",
    "    model.optimize\n",
    "    model.tensorboard_init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect DPCL model to the front end and back end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = model.non_initialized_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_iterations = 1000\n",
    "#initialize the model\n",
    "model.sess.run(init)\n",
    "\n",
    "for i in range(nb_iterations):\n",
    "    X_in, X_mix, Ind = mixed_data.get_batch(batch_size)\n",
    "    c = model.train(X_mix, X_in, learning_rate, i)\n",
    "    print 'Step #'  ,i,' loss=', c \n",
    "\n",
    "    if i%20 == 0: #cost_valid < cost_valid_min:\n",
    "        print 'DAS model saved at iteration number ', i,' with cost = ', c \n",
    "        model.save(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
