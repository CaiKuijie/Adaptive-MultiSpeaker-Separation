{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are on PC\n"
     ]
    }
   ],
   "source": [
    "from data.dataset import H5PY_RW\n",
    "from data.data_tools import read_metadata, males_keys, females_keys\n",
    "\n",
    "H5_dic = read_metadata()\n",
    "\n",
    "chunk_size = 512*10\n",
    "\n",
    "males = H5PY_RW('test_raw_16k.h5py', subset = males_keys(H5_dic)).set_chunk(chunk_size) # males voices dataset\n",
    "females = H5PY_RW('test_raw_16k.h5py', subset = females_keys(H5_dic)).set_chunk(chunk_size=chunk_size) # females voices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import Mixer\n",
    "\n",
    "# Use validation set\n",
    "mix_mf = Mixer([males, females], with_mask=False, with_inputs=True, shuffling=True).select_split(2)\n",
    "mix_mm = Mixer([males, males], with_mask=False, with_inputs=True, shuffling=True).select_split(2)\n",
    "mix_ff = Mixer([females, females], with_mask=False, with_inputs=True, shuffling=True).select_split(2)\n",
    "\n",
    "mixers = [mix_mf, mix_ff, mix_ff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/anthony/das/log/DPCL_finetuning/AdaptiveNet-royal-pond-5964-N=256--alpha=0.001--batch_size=1--beta=0.1--chunk_size=5120--maxpool=128--reg=0.0001--rho=0.01--smooth_size=20--type=DPCL_finetuning--window=1024-/SavedModel/variables/variables\n",
      "z\n",
      "z\n",
      "z\n",
      "[-1.7332590225796352, -1.1553780162181404, -3.1974157889507131] [0.73670325590756902, 1.6137457178537065, -0.12202363946564318] [-252.20321786861169, -260.09549921550968, -249.89236130090981]\n"
     ]
    }
   ],
   "source": [
    "from utils.bss_eval import bss_eval_sources\n",
    "import numpy as np\n",
    "## implement model loading directly, SavedModel since we don't have to modify the architecture here.\n",
    "\n",
    "path = '/home/anthony/das/log/DPCL_finetuning/AdaptiveNet-royal-pond-5964-N=256--alpha=0.001--batch_size=1--beta=0.1--chunk_size=5120--maxpool=128--reg=0.0001--rho=0.01--smooth_size=20--type=DPCL_finetuning--window=1024-/SavedModel'\n",
    "nb_iterations = 10\n",
    "\n",
    "sdr = [0.0 for i in range(len(mixers))]\n",
    "sir = [0.0 for i in range(len(mixers))]\n",
    "sar = [0.0 for i in range(len(mixers))]\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, ['validating'], path)\n",
    "#     show_graph(tf.get_default_graph().as_graph_def())\n",
    "#     print tf.get_default_graph().get_operations()\n",
    "    for j, mixer in enumerate(mixers):\n",
    "        print 'z'\n",
    "        for i in range(nb_iterations):\n",
    "            non_mix_input, mix_input , ind = mixer.get_batch(1)\n",
    "            \n",
    "            input = tf.get_default_graph().get_operation_by_name('mix_input').values()[0]\n",
    "            non_input = tf.get_default_graph().get_operation_by_name('non_mix_input').values()[0]\n",
    "            back = tf.get_default_graph().get_operation_by_name('back/back_output').values()[0]\n",
    "            is_training = tf.get_default_graph().get_operation_by_name('is_training').values()[0]\n",
    "            test = tf.get_default_graph().get_operation_by_name('front/MaxPoolWithArgmax').values()[0]\n",
    "            unmix = sess.run(back, feed_dict={input: mix_input, non_input: non_mix_input,is_training:False})\n",
    "            \n",
    "            unmix = np.reshape(unmix, (2, chunk_size))\n",
    "            mix_input = np.reshape(mix_input, (chunk_size))\n",
    "            mix_stack = np.array([mix_input, mix_input])\n",
    "            \n",
    "            no_separation = bss_eval_sources(np.squeeze(non_mix_input), mix_stack)\n",
    "            \n",
    "            separation = bss_eval_sources(np.squeeze(non_mix_input), unmix)\n",
    "            \n",
    "            sdr[j] += np.mean(separation[0] - no_separation[0])\n",
    "            sir[j] += np.mean(separation[1] - no_separation[1])\n",
    "            sar[j] += np.mean(separation[2] - no_separation[2])\n",
    "        \n",
    "        sdr[j] /= float(nb_iterations) \n",
    "        sir[j] /= float(nb_iterations) \n",
    "        sar[j] /= float(nb_iterations)\n",
    "print sdr, sir, sar\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
