{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get your datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 40 male and female speakers\n",
      "4397 elements\n",
      "4382 elements\n"
     ]
    }
   ],
   "source": [
    "from data.dataset import H5PY_RW\n",
    "from data.data_tools import read_data_header, males_keys, females_keys\n",
    "\n",
    "H5_dic = read_data_header()\n",
    "chunk_size = 512*30\n",
    "\n",
    "males = H5PY_RW().open_h5_dataset('test_raw.h5py', subset = males_keys(H5_dic)).set_chunk(chunk_size).shuffle()\n",
    "fem = H5PY_RW().open_h5_dataset('test_raw.h5py', subset = females_keys(H5_dic)).set_chunk(chunk_size).shuffle()\n",
    "print 'Data with', len(H5_dic), 'male and female speakers'\n",
    "print males.length(), 'elements'\n",
    "print fem.length(), 'elements'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import Mixer\n",
    "\n",
    "mixed_data = Mixer([males, fem], with_mask=False, with_inputs=True)\n",
    "\n",
    "# Training set selection\n",
    "mixed_data.select_split(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "max_pool = 128\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "config_model = {}\n",
    "config_model[\"type\"] = \"pretraining\"\n",
    "\n",
    "config_model[\"batch_size\"] = batch_size\n",
    "config_model[\"chunk_size\"] = chunk_size\n",
    "\n",
    "config_model[\"N\"] = N\n",
    "config_model[\"maxpool\"] = max_pool\n",
    "config_model[\"window\"] = 1024\n",
    "\n",
    "config_model[\"smooth_size\"] = 20\n",
    "\n",
    "config_model[\"alpha\"] = learning_rate\n",
    "config_model[\"reg\"] = 1e-4\n",
    "config_model[\"beta\"] = 0.1\n",
    "config_model[\"rho\"] = 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID : AdaptiveNet-rapid-water-2147\n",
      "[<tf.Variable 'conv/W:0' shape=(1, 1024, 1, 256) dtype=float32_ref>, <tf.Variable 'deconv/WT:0' shape=(1, 1024, 1, 256) dtype=float32_ref>, <tf.Variable 'smooth/smoothing_filter:0' shape=(1, 20, 256, 256) dtype=float32_ref>]\n",
      "Total name :\n",
      "AdaptiveNet-rapid-water-2147-N=256--alpha=0.001--batch_size=1--beta=0.1--chunk_size=15360--maxpool=128--reg=0.0001--rho=0.05--smooth_size=20--type=pretraining--window=1024-\n"
     ]
    }
   ],
   "source": [
    "from models.adapt import Adapt\n",
    "\n",
    "adapt_model = Adapt(config_model=config_model, pretraining=True, folder='pretraining')\n",
    "print 'Total name :' \n",
    "print adapt_model.runID\n",
    "adapt_model.tensorboard_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step # 0  loss= 0.759443\n",
      "DAS model saved at iteration number  0  with cost =  0.759443\n",
      "Step # 1  loss= 0.694683\n",
      "Step # 2  loss= 0.640291\n",
      "Step # 3  loss= 0.631551\n",
      "Step # 4  loss= 0.475101\n",
      "Step # 5  loss= 0.392115\n",
      "Step # 6  loss= 0.593143\n",
      "Step # 7  loss= 0.481935\n",
      "Step # 8  loss= 0.65757\n",
      "Step # 9  loss= 0.329286\n",
      "Step # 10  loss= 0.451102\n",
      "Step # 11  loss= 0.599127\n",
      "Step # 12  loss= 0.377243\n",
      "Step # 13  loss= 0.189822\n",
      "Step # 14  loss= 0.186707\n",
      "Step # 15  loss= 0.393727\n",
      "Step # 16  loss= 0.277342\n",
      "Step # 17  loss= 0.33335\n",
      "Step # 18  loss= 0.339616\n",
      "Step # 19  loss= 0.332901\n",
      "Step # 20  loss= 0.23364\n",
      "DAS model saved at iteration number  20  with cost =  0.23364\n",
      "Step # 21  loss= 0.26682\n",
      "Step # 22  loss= 0.228428\n",
      "Step # 23  loss= 0.288753\n",
      "Step # 24  loss= 0.284649\n",
      "Step # 25  loss= 0.292417\n",
      "Step # 26  loss= 0.403939\n",
      "Step # 27  loss= 0.219317\n",
      "Step # 28  loss= 0.375505\n",
      "Step # 29  loss= 0.165311\n",
      "Step # 30  loss= 0.249726\n",
      "Step # 31  loss= 0.433522\n",
      "Step # 32  loss= 0.245869\n",
      "Step # 33  loss= 0.216888\n",
      "Step # 34  loss= 0.243845\n",
      "Step # 35  loss= 0.200165\n",
      "Step # 36  loss= 0.148608\n",
      "Step # 37  loss= 0.364704\n",
      "Step # 38  loss= 0.164988\n",
      "Step # 39  loss= 0.289797\n",
      "Step # 40  loss= 0.440093\n",
      "DAS model saved at iteration number  40  with cost =  0.440093\n",
      "Step # 41  loss= 0.208113\n",
      "Step # 42  loss= 0.181414\n",
      "Step # 43  loss= 0.202225\n",
      "Step # 44  loss= 0.346258\n",
      "Step # 45  loss= 0.396332\n",
      "Step # 46  loss= 0.246018\n",
      "Step # 47  loss= 0.21652\n",
      "Step # 48  loss= 0.335288\n",
      "Step # 49  loss= 0.229915\n",
      "Step # 50  loss= 0.111215\n",
      "Step # 51  loss= 0.198346\n",
      "Step # 52  loss= 0.14474\n",
      "Step # 53  loss= 0.126067\n",
      "Step # 54  loss= 0.168156\n",
      "Step # 55  loss= 0.139339\n",
      "Step # 56  loss= 0.142228\n",
      "Step # 57  loss= 0.173394\n",
      "Step # 58  loss= 0.318472\n",
      "Step # 59  loss= 0.164782\n",
      "Step # 60  loss= 0.198627\n",
      "DAS model saved at iteration number  60  with cost =  0.198627\n",
      "Step # 61  loss= 0.189408\n",
      "Step # 62  loss= 0.185247\n",
      "Step # 63  loss= 0.133094\n",
      "Step # 64  loss= 0.184853\n",
      "Step # 65  loss= 0.163257\n",
      "Step # 66  loss= 0.179703\n",
      "Step # 67  loss= 0.14688\n",
      "Step # 68  loss= 0.179781\n",
      "Step # 69  loss= 0.231249\n",
      "Step # 70  loss= 0.195658\n",
      "Step # 71  loss= 0.252972\n",
      "Step # 72  loss= 0.166516\n",
      "Step # 73  loss= 0.18124\n",
      "Step # 74  loss= 0.222071\n",
      "Step # 75  loss= 0.197403\n",
      "Step # 76  loss= 0.110006\n",
      "Step # 77  loss= 0.207991\n",
      "Step # 78  loss= 0.155716\n",
      "Step # 79  loss= 0.0951659\n",
      "Step # 80  loss= 0.294812\n",
      "DAS model saved at iteration number  80  with cost =  0.294812\n",
      "Step # 81  loss= 0.215719\n",
      "Step # 82  loss= 0.130781\n",
      "Step # 83  loss= 0.196064\n",
      "Step # 84  loss= 0.327102\n",
      "Step # 85  loss= 0.151941\n",
      "Step # 86  loss= 0.249379\n",
      "Step # 87  loss= 0.184574\n",
      "Step # 88  loss= 0.253391\n",
      "Step # 89  loss= 0.224591\n",
      "Step # 90  loss= 0.226506\n",
      "Step # 91  loss= 0.136339\n",
      "Step # 92  loss= 0.198854\n",
      "Step # 93  loss= 0.177205\n",
      "Step # 94  loss= 0.327873\n",
      "Step # 95  loss= 0.223995\n",
      "Step # 96  loss= 0.189092\n",
      "Step # 97  loss= 0.223849\n",
      "Step # 98  loss= 0.13741\n",
      "Step # 99  loss= 0.234371\n",
      "Step # 100  loss= 0.164741\n",
      "DAS model saved at iteration number  100  with cost =  0.164741\n",
      "Step # 101  loss= 0.0787753\n",
      "Step # 102  loss= 0.640169\n",
      "Step # 103  loss= 0.154028\n",
      "Step # 104  loss= 0.20994\n",
      "Step # 105  loss= 0.149435\n",
      "Step # 106  loss= 0.219652\n",
      "Step # 107  loss= 0.149831\n",
      "Step # 108  loss= 0.167359\n",
      "Step # 109  loss= 0.193314\n",
      "Step # 110  loss= 0.220234\n",
      "Step # 111  loss= 0.146385\n",
      "Step # 112  loss= 0.264207\n",
      "Step # 113  loss= 0.171272\n",
      "Step # 114  loss= 0.141244\n",
      "Step # 115  loss= 0.224456\n",
      "Step # 116  loss= 0.166674\n",
      "Step # 117  loss= 0.164155\n",
      "Step # 118  loss= 0.243337\n",
      "Step # 119  loss= 0.291952\n",
      "Step # 120  loss= 0.202827\n",
      "DAS model saved at iteration number  120  with cost =  0.202827\n",
      "Step # 121  loss= 0.212045\n",
      "Step # 122  loss= 0.1716\n",
      "Step # 123  loss= 0.208195\n",
      "Step # 124  loss= 0.179526\n",
      "Step # 125  loss= 0.207175\n",
      "Step # 126  loss= 0.173394\n",
      "Step # 127  loss= 0.212562\n",
      "Step # 128  loss= 0.205816\n",
      "Step # 129  loss= 0.28998\n",
      "Step # 130  loss= 0.165311\n",
      "Step # 131  loss= 0.152016\n",
      "Step # 132  loss= 0.207494\n",
      "Step # 133  loss= 0.123577\n",
      "Step # 134  loss= 0.224632\n",
      "Step # 135  loss= 0.10147\n",
      "Step # 136  loss= 0.258077\n",
      "Step # 137  loss= 0.207018\n",
      "Step # 138  loss= 0.254267\n",
      "Step # 139  loss= 0.182556\n",
      "Step # 140  loss= 0.188771\n",
      "DAS model saved at iteration number  140  with cost =  0.188771\n",
      "Step # 141  loss= 0.235523\n",
      "Step # 142  loss= 0.233436\n",
      "Step # 143  loss= 0.280639\n",
      "Step # 144  loss= 0.478252\n",
      "Step # 145  loss= 0.177042\n",
      "Step # 146  loss= 0.154388\n",
      "Step # 147  loss= 0.16583\n",
      "Step # 148  loss= 0.210665\n",
      "Step # 149  loss= 0.26313\n",
      "Step # 150  loss= 0.358399\n",
      "Step # 151  loss= 0.218727\n",
      "Step # 152  loss= 0.19578\n",
      "Step # 153  loss= 0.192854\n",
      "Step # 154  loss= 0.241915\n",
      "Step # 155  loss= 0.17185\n",
      "Step # 156  loss= 0.229239\n",
      "Step # 157  loss= 0.154258\n",
      "Step # 158  loss= 0.14483\n",
      "Step # 159  loss= 0.244235\n",
      "Step # 160  loss= 0.19321\n",
      "DAS model saved at iteration number  160  with cost =  0.19321\n",
      "Step # 161  loss= 0.204502\n",
      "Step # 162  loss= 0.159217\n",
      "Step # 163  loss= 0.206184\n",
      "Step # 164  loss= 0.135099\n",
      "Step # 165  loss= 0.236699\n",
      "Step # 166  loss= 0.130377\n",
      "Step # 167  loss= 0.123073\n",
      "Step # 168  loss= 0.217862\n",
      "Step # 169  loss= 0.128427\n",
      "Step # 170  loss= 0.155542\n",
      "Step # 171  loss= 0.243575\n",
      "Step # 172  loss= 0.221118\n",
      "Step # 173  loss= 0.16952\n",
      "Step # 174  loss= 0.196767\n",
      "Step # 175  loss= 0.119791\n",
      "Step # 176  loss= 0.404157\n",
      "Step # 177  loss= 0.126684\n",
      "Step # 178  loss= 0.268473\n",
      "Step # 179  loss= 0.134557\n",
      "Step # 180  loss= 0.346106\n",
      "DAS model saved at iteration number  180  with cost =  0.346106\n",
      "Step # 181  loss= 0.195654\n",
      "Step # 182  loss= 0.0899056\n",
      "Step # 183  loss= 0.141505\n",
      "Step # 184  loss= 0.183033\n",
      "Step # 185  loss= 0.155695\n",
      "Step # 186  loss= 0.123042\n",
      "Step # 187  loss= 0.183892\n",
      "Step # 188  loss= 0.284183\n",
      "Step # 189  loss= 0.155098\n",
      "Step # 190  loss= 0.285363\n",
      "Step # 191  loss= 0.199728\n",
      "Step # 192  loss= 0.172735\n",
      "Step # 193  loss= 0.163636\n",
      "Step # 194  loss= 0.183499\n",
      "Step # 195  loss= 0.182472\n",
      "Step # 196  loss= 0.151016\n",
      "Step # 197  loss= 0.160532\n",
      "Step # 198  loss= 0.271555\n",
      "Step # 199  loss= 0.297991\n",
      "Step # 200  loss= 0.171043\n",
      "DAS model saved at iteration number  200  with cost =  0.171043\n",
      "Step # 201  loss= 0.193443\n",
      "Step # 202  loss= 0.234836\n",
      "Step # 203  loss= 0.209295\n",
      "Step # 204  loss= 0.134974\n",
      "Step # 205  loss= 0.292331\n",
      "Step # 206  loss= 0.125337\n",
      "Step # 207  loss= 0.29869\n",
      "Step # 208  loss= 0.206386\n",
      "Step # 209  loss= 0.191152\n",
      "Step # 210  loss= 0.335968\n",
      "Step # 211  loss= 0.127845\n",
      "Step # 212  loss= 0.21872\n",
      "Step # 213  loss= 0.161913\n",
      "Step # 214  loss= 0.150568\n",
      "Step # 215  loss= 0.194941\n",
      "Step # 216  loss= 0.25144\n",
      "Step # 217  loss= 0.178507\n",
      "Step # 218  loss= 0.183575\n",
      "Step # 219  loss= 0.21202\n",
      "Step # 220  loss= 0.462096\n",
      "DAS model saved at iteration number  220  with cost =  0.462096\n",
      "Step # 221  loss= 0.310169\n",
      "Step # 222  loss= 0.20907\n",
      "Step # 223  loss= 0.163207\n"
     ]
    }
   ],
   "source": [
    "nb_iterations = 1000\n",
    "\n",
    "#initialize the model\n",
    "adapt_model.init()\n",
    "\n",
    "\n",
    "for i in range(nb_iterations):\n",
    "    X_in, X_mix, Ind = mixed_data.get_batch(batch_size)\n",
    "    c = adapt_model.train(X_mix, X_in, learning_rate, i)\n",
    "    print 'Step #'  ,i,' loss=', c \n",
    "\n",
    "    if i%20 == 0: #cost_valid < cost_valid_min:\n",
    "        print 'DAS model saved at iteration number ', i,' with cost = ', c \n",
    "        adapt_model.save(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
