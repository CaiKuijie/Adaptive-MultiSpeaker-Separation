{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get your datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 40 male and female speakers\n"
     ]
    }
   ],
   "source": [
    "from data.dataset import H5PY_RW\n",
    "from data.data_tools import read_metadata, males_keys, females_keys\n",
    "\n",
    "H5_dic = read_metadata()\n",
    "chunk_size = 512*10\n",
    "\n",
    "males = H5PY_RW('test_raw_16k.h5py', subset = males_keys(H5_dic)).set_chunk(chunk_size).shuffle()\n",
    "fem = H5PY_RW('test_raw_16k.h5py', subset = females_keys(H5_dic)).set_chunk(chunk_size).shuffle()\n",
    "print 'Data with', len(H5_dic), 'male and female speakers'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import Mixer\n",
    "\n",
    "mixed_data = Mixer([males, fem], with_mask=False, with_inputs=True)\n",
    "\n",
    "# Training set selection\n",
    "mixed_data.select_split(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model pretrained loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "max_pool = 128\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "\n",
    "config_model = {}\n",
    "config_model[\"type\"] = \"pretraining\"\n",
    "\n",
    "config_model[\"batch_size\"] = batch_size\n",
    "config_model[\"chunk_size\"] = chunk_size\n",
    "\n",
    "config_model[\"N\"] = N\n",
    "config_model[\"maxpool\"] = max_pool\n",
    "config_model[\"window\"] = 1024\n",
    "\n",
    "config_model[\"smooth_size\"] = 20\n",
    "\n",
    "config_model[\"alpha\"] = learning_rate\n",
    "config_model[\"reg\"] = 1e-4\n",
    "config_model[\"beta\"] = 0.1\n",
    "config_model[\"rho\"] = 0.01\n",
    "\n",
    "idd = ''.join('-{}={}-'.format(key, val) for key, val in sorted(config_model.items()))\n",
    "config_model[\"type\"] = \"DPCL_train_front\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID : AdaptiveNet-wispy-forest-8617\n",
      "INFO:tensorflow:Restoring parameters from /home/anthony/das/floydhub_model/pretraining/AdaptiveNet-soft-base-9900-N=256--alpha=0.001--batch_size=8--beta=0.1--chunk_size=5120--maxpool=128--reg=0.0001--rho=0.01--smooth_size=20--type=pretraining--window=1024-/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "from models.adapt import Adapt\n",
    "import config\n",
    "\n",
    "full_id = 'soft-base-9900'+idd\n",
    "\n",
    "folder='DPCL_train_front'\n",
    "model = Adapt(config_model=config_model,pretraining=False)\n",
    "model.create_saver()\n",
    "\n",
    "path = os.path.join(config.workdir, 'floydhub_model', \"pretraining\")\n",
    "# path = os.path.join(config.log_dir, \"pretraining\")\n",
    "model.restore_model(path, full_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect DPCL model to the front end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"prediction/l2_normalize:0\", shape=(?, ?, 256, 40), dtype=float32)\n",
      "[<tf.Variable 'prediction/W:0' shape=(1, 600, 10240) dtype=float32_ref>, <tf.Variable 'prediction/b:0' shape=(10240,) dtype=float32_ref>, <tf.Variable 'prediction/forward_BLSTM_1/rnn/basic_lstm_cell/kernel:0' shape=(556, 1200) dtype=float32_ref>, <tf.Variable 'prediction/forward_BLSTM_1/rnn/basic_lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'prediction/backward_BLSTM_1/rnn/basic_lstm_cell/kernel:0' shape=(556, 1200) dtype=float32_ref>, <tf.Variable 'prediction/backward_BLSTM_1/rnn/basic_lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'prediction/forward_BLSTM_2/rnn/basic_lstm_cell/kernel:0' shape=(900, 1200) dtype=float32_ref>, <tf.Variable 'prediction/forward_BLSTM_2/rnn/basic_lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'prediction/backward_BLSTM_2/rnn/basic_lstm_cell/kernel:0' shape=(900, 1200) dtype=float32_ref>, <tf.Variable 'prediction/backward_BLSTM_2/rnn/basic_lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "from models.dpcl import DPCL\n",
    "\n",
    "with model.graph.as_default():\n",
    "    model.connect_front(DPCL)\n",
    "    model.sepNet.output = model.sepNet.prediction\n",
    "    model.cost = model.sepNet.cost\n",
    "    model.freeze_front()\n",
    "    model.optimize\n",
    "    model.tensorboard_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'prediction/W:0' shape=(1, 600, 10240) dtype=float32_ref>, <tf.Variable 'prediction/b:0' shape=(10240,) dtype=float32_ref>, <tf.Variable 'prediction/forward_BLSTM_1/rnn/basic_lstm_cell/kernel:0' shape=(556, 1200) dtype=float32_ref>, <tf.Variable 'prediction/forward_BLSTM_1/rnn/basic_lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'prediction/backward_BLSTM_1/rnn/basic_lstm_cell/kernel:0' shape=(556, 1200) dtype=float32_ref>, <tf.Variable 'prediction/backward_BLSTM_1/rnn/basic_lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'prediction/forward_BLSTM_2/rnn/basic_lstm_cell/kernel:0' shape=(900, 1200) dtype=float32_ref>, <tf.Variable 'prediction/forward_BLSTM_2/rnn/basic_lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'prediction/backward_BLSTM_2/rnn/basic_lstm_cell/kernel:0' shape=(900, 1200) dtype=float32_ref>, <tf.Variable 'prediction/backward_BLSTM_2/rnn/basic_lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/W/RMSProp:0' shape=(1, 600, 10240) dtype=float32_ref>, <tf.Variable 'optimize/prediction/W/RMSProp_1:0' shape=(1, 600, 10240) dtype=float32_ref>, <tf.Variable 'optimize/prediction/b/RMSProp:0' shape=(10240,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/b/RMSProp_1:0' shape=(10240,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/forward_BLSTM_1/rnn/basic_lstm_cell/kernel/RMSProp:0' shape=(556, 1200) dtype=float32_ref>, <tf.Variable 'optimize/prediction/forward_BLSTM_1/rnn/basic_lstm_cell/kernel/RMSProp_1:0' shape=(556, 1200) dtype=float32_ref>, <tf.Variable 'optimize/prediction/forward_BLSTM_1/rnn/basic_lstm_cell/bias/RMSProp:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/forward_BLSTM_1/rnn/basic_lstm_cell/bias/RMSProp_1:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/backward_BLSTM_1/rnn/basic_lstm_cell/kernel/RMSProp:0' shape=(556, 1200) dtype=float32_ref>, <tf.Variable 'optimize/prediction/backward_BLSTM_1/rnn/basic_lstm_cell/kernel/RMSProp_1:0' shape=(556, 1200) dtype=float32_ref>, <tf.Variable 'optimize/prediction/backward_BLSTM_1/rnn/basic_lstm_cell/bias/RMSProp:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/backward_BLSTM_1/rnn/basic_lstm_cell/bias/RMSProp_1:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/forward_BLSTM_2/rnn/basic_lstm_cell/kernel/RMSProp:0' shape=(900, 1200) dtype=float32_ref>, <tf.Variable 'optimize/prediction/forward_BLSTM_2/rnn/basic_lstm_cell/kernel/RMSProp_1:0' shape=(900, 1200) dtype=float32_ref>, <tf.Variable 'optimize/prediction/forward_BLSTM_2/rnn/basic_lstm_cell/bias/RMSProp:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/forward_BLSTM_2/rnn/basic_lstm_cell/bias/RMSProp_1:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/backward_BLSTM_2/rnn/basic_lstm_cell/kernel/RMSProp:0' shape=(900, 1200) dtype=float32_ref>, <tf.Variable 'optimize/prediction/backward_BLSTM_2/rnn/basic_lstm_cell/kernel/RMSProp_1:0' shape=(900, 1200) dtype=float32_ref>, <tf.Variable 'optimize/prediction/backward_BLSTM_2/rnn/basic_lstm_cell/bias/RMSProp:0' shape=(1200,) dtype=float32_ref>, <tf.Variable 'optimize/prediction/backward_BLSTM_2/rnn/basic_lstm_cell/bias/RMSProp_1:0' shape=(1200,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "from itertools import compress\n",
    "with model.graph.as_default():\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = model.sess.run([~(tf.is_variable_initialized(var)) \\\n",
    "                                   for var in global_vars])\n",
    "    not_initialized_vars = list(compress(global_vars, is_not_initialized))\n",
    "    print not_initialized_vars\n",
    "    if len(not_initialized_vars):\n",
    "        init = tf.variables_initializer(not_initialized_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step # 0  loss= 110.018\n",
      "DAS model saved at iteration number  0  with cost =  110.018\n",
      "Step # 1  loss= 103.141\n",
      "Step # 2  loss= 97.1314\n",
      "Step # 3  loss= 93.5372\n",
      "Step # 4  loss= 89.62\n",
      "Step # 5  loss= 87.0062\n",
      "Step # 6  loss= 85.6691\n",
      "Step # 7  loss= 83.2059\n",
      "Step # 8  loss= 81.6887\n",
      "Step # 9  loss= 79.4571\n",
      "Step # 10  loss= 77.8962\n",
      "Step # 11  loss= 77.3552\n",
      "Step # 12  loss= 76.932\n",
      "Step # 13  loss= 75.8065\n",
      "Step # 14  loss= 75.296\n",
      "Step # 15  loss= 75.0277\n",
      "Step # 16  loss= 74.7348\n",
      "Step # 17  loss= 73.1299\n",
      "Step # 18  loss= 73.4137\n",
      "Step # 19  loss= 73.7363\n",
      "Step # 20  loss= 73.0521\n",
      "DAS model saved at iteration number  20  with cost =  73.0521\n",
      "Step # 21  loss= 72.4501\n",
      "Step # 22  loss= 72.8737\n",
      "Step # 23  loss= 72.354\n",
      "Step # 24  loss= 71.8575\n",
      "Step # 25  loss= 71.7113\n",
      "Step # 26  loss= 72.0687\n",
      "Step # 27  loss= 72.5334\n",
      "Step # 28  loss= 72.239\n",
      "Step # 29  loss= 71.8977\n",
      "Step # 30  loss= 71.5458\n",
      "Step # 31  loss= 71.2849\n",
      "Step # 32  loss= 70.973\n",
      "Step # 33  loss= 71.0748\n",
      "Step # 34  loss= 71.0125\n",
      "Step # 35  loss= 70.2797\n",
      "Step # 36  loss= 70.7532\n",
      "Step # 37  loss= 70.1031\n",
      "Step # 38  loss= 70.0521\n",
      "Step # 39  loss= 70.6569\n",
      "Step # 40  loss= 70.3332\n",
      "DAS model saved at iteration number  40  with cost =  70.3332\n",
      "Step # 41  loss= 70.2409\n",
      "Step # 42  loss= 70.4575\n",
      "Step # 43  loss= 69.7069\n",
      "Step # 44  loss= 69.7471\n",
      "Step # 45  loss= 69.8674\n",
      "Step # 46  loss= 69.874\n",
      "Step # 47  loss= 69.3315\n",
      "Step # 48  loss= 69.1752\n",
      "Step # 49  loss= 69.4139\n",
      "Step # 50  loss= 69.5738\n",
      "Step # 51  loss= 69.4904\n",
      "Step # 52  loss= 69.4316\n",
      "Step # 53  loss= 69.5409\n",
      "Step # 54  loss= 69.5506\n",
      "Step # 55  loss= 68.7687\n",
      "Step # 56  loss= 69.7419\n",
      "Step # 57  loss= 69.1432\n",
      "Step # 58  loss= 68.4815\n",
      "Step # 59  loss= 68.963\n",
      "Step # 60  loss= 69.3659\n",
      "DAS model saved at iteration number  60  with cost =  69.3659\n",
      "Step # 61  loss= 68.409\n",
      "Step # 62  loss= 68.6519\n",
      "Step # 63  loss= 68.6617\n",
      "Step # 64  loss= 68.5857\n",
      "Step # 65  loss= 68.1955\n",
      "Step # 66  loss= 68.6986\n",
      "Step # 67  loss= 68.7494\n",
      "Step # 68  loss= 68.7006\n",
      "Step # 69  loss= 68.3597\n",
      "Step # 70  loss= 68.608\n",
      "Step # 71  loss= 67.557\n",
      "Step # 72  loss= 68.212\n",
      "Step # 73  loss= 68.5616\n",
      "Step # 74  loss= 68.3916\n",
      "Step # 75  loss= 67.8742\n",
      "Step # 76  loss= 67.6824\n",
      "Step # 77  loss= 67.7673\n",
      "Step # 78  loss= 67.568\n",
      "Step # 79  loss= 67.7362\n",
      "Step # 80  loss= 67.0771\n",
      "DAS model saved at iteration number  80  with cost =  67.0771\n",
      "Step # 81  loss= 67.9799\n",
      "Step # 82  loss= 67.4125\n",
      "Step # 83  loss= 67.6053\n",
      "Step # 84  loss= 67.8215\n",
      "Step # 85  loss= 67.7158\n",
      "Step # 86  loss= 67.5785\n",
      "Step # 87  loss= 67.5358\n",
      "Step # 88  loss= 66.6646\n",
      "Step # 89  loss= 67.1383\n",
      "Step # 90  loss= 67.7891\n",
      "Step # 91  loss= 67.3705\n",
      "Step # 92  loss= 67.107\n",
      "Step # 93  loss= 67.4666\n",
      "Step # 94  loss= 67.7735\n",
      "Step # 95  loss= 67.8892\n",
      "Step # 96  loss= 67.413\n",
      "Step # 97  loss= 67.3487\n",
      "Step # 98  loss= 67.4643\n",
      "Step # 99  loss= 67.1048\n",
      "Step # 100  loss= 67.6775\n",
      "DAS model saved at iteration number  100  with cost =  67.6775\n",
      "Step # 101  loss= 67.491\n",
      "Step # 102  loss= 66.934\n",
      "Step # 103  loss= 67.5152\n",
      "Step # 104  loss= 67.942\n",
      "Step # 105  loss= 66.9264\n",
      "Step # 106  loss= 67.7197\n",
      "Step # 107  loss= 66.7238\n",
      "Step # 108  loss= 67.3438\n",
      "Step # 109  loss= 66.638\n",
      "Step # 110  loss= 66.772\n",
      "Step # 111  loss= 67.5077\n",
      "Step # 112  loss= 67.2711\n",
      "Step # 113  loss= 67.2098\n",
      "Step # 114  loss= 67.3906\n",
      "Step # 115  loss= 67.5074\n",
      "Step # 116  loss= 67.1876\n",
      "Step # 117  loss= 66.8291\n",
      "Step # 118  loss= 66.8421\n",
      "Step # 119  loss= 66.9649\n",
      "Step # 120  loss= 66.9123\n",
      "DAS model saved at iteration number  120  with cost =  66.9123\n",
      "Step # 121  loss= 67.433\n",
      "Step # 122  loss= 66.0213\n",
      "Step # 123  loss= 66.8623\n",
      "Step # 124  loss= 66.5334\n",
      "Step # 125  loss= 66.954\n",
      "Step # 126  loss= 66.2875\n",
      "Step # 127  loss= 66.6455\n",
      "Step # 128  loss= 66.1485\n",
      "Step # 129  loss= 66.9006\n",
      "Step # 130  loss= 66.5408\n",
      "Step # 131  loss= 66.0072\n",
      "Step # 132  loss= 66.601\n",
      "Step # 133  loss= 65.7626\n",
      "Step # 134  loss= 66.4126\n",
      "Step # 135  loss= 65.9578\n",
      "Step # 136  loss= 66.1617\n",
      "Step # 137  loss= 65.3965\n",
      "Step # 138  loss= 65.3509\n",
      "Step # 139  loss= 65.4751\n",
      "Step # 140  loss= 65.8564\n",
      "DAS model saved at iteration number  140  with cost =  65.8564\n",
      "Step # 141  loss= 66.0109\n",
      "Step # 142  loss= 65.8065\n",
      "Step # 143  loss= 65.1387\n",
      "Step # 144  loss= 65.7836\n",
      "Step # 145  loss= 65.3798\n",
      "Step # 146  loss= 64.6914\n",
      "Step # 147  loss= 64.6062\n",
      "Step # 148  loss= 64.535\n",
      "Step # 149  loss= 63.812\n",
      "Step # 150  loss= 64.2515\n",
      "Step # 151  loss= 64.3098\n",
      "Step # 152  loss= 64.1666\n",
      "Step # 153  loss= 63.9608\n",
      "Step # 154  loss= 63.9156\n",
      "Step # 155  loss= 64.0768\n",
      "Step # 156  loss= 63.2425\n",
      "Step # 157  loss= 63.5984\n",
      "Step # 158  loss= 63.2859\n",
      "Step # 159  loss= 62.4493\n",
      "Step # 160  loss= 63.4789\n",
      "DAS model saved at iteration number  160  with cost =  63.4789\n",
      "Step # 161  loss= 62.9082\n",
      "Step # 162  loss= 62.5975\n",
      "Step # 163  loss= 62.6227\n",
      "Step # 164  loss= 62.0012\n",
      "Step # 165  loss= 62.0012\n",
      "Step # 166  loss= 60.6551\n",
      "Step # 167  loss= 61.223\n",
      "Step # 168  loss= 62.0227\n",
      "Step # 169  loss= 60.7525\n",
      "Step # 170  loss= 61.1036\n",
      "Step # 171  loss= 60.9213\n",
      "Step # 172  loss= 60.5233\n",
      "Step # 173  loss= 60.7692\n",
      "Step # 174  loss= 60.6247\n",
      "Step # 175  loss= 59.702\n",
      "Step # 176  loss= 59.9773\n",
      "Step # 177  loss= 59.6597\n",
      "Step # 178  loss= 59.3281\n",
      "Step # 179  loss= 58.8369\n",
      "Step # 180  loss= 57.8648\n",
      "DAS model saved at iteration number  180  with cost =  57.8648\n",
      "Step # 181  loss= 58.5431\n",
      "Step # 182  loss= 58.7933\n",
      "Step # 183  loss= 57.5447\n",
      "Step # 184  loss= 57.6787\n",
      "Step # 185  loss= 57.3286\n",
      "Step # 186  loss= 56.6326\n",
      "Step # 187  loss= 57.0168\n",
      "Step # 188  loss= 55.7133\n",
      "Step # 189  loss= 55.7237\n",
      "Step # 190  loss= 55.2563\n",
      "Step # 191  loss= 55.7221\n",
      "Step # 192  loss= 55.4108\n",
      "Step # 193  loss= 55.1023\n",
      "Step # 194  loss= 54.6389\n",
      "Step # 195  loss= 54.4537\n",
      "Step # 196  loss= 54.4113\n",
      "Step # 197  loss= 54.022\n",
      "Step # 198  loss= 53.5616\n",
      "Step # 199  loss= 53.4058\n",
      "Step # 200  loss= 53.6247\n",
      "DAS model saved at iteration number  200  with cost =  53.6247\n",
      "Step # 201  loss= 53.6486\n",
      "Step # 202  loss= 52.4267\n",
      "Step # 203  loss= 52.6388\n",
      "Step # 204  loss= 51.7074\n",
      "Step # 205  loss= 52.0513\n",
      "Step # 206  loss= 51.3226\n",
      "Step # 207  loss= 51.4348\n",
      "Step # 208  loss= 51.0984\n",
      "Step # 209  loss= 50.2793\n",
      "Step # 210  loss= 50.6369\n",
      "Step # 211  loss= 50.2529\n",
      "Step # 212  loss= 49.954\n",
      "Step # 213  loss= 49.4327\n",
      "Step # 214  loss= 49.2686\n",
      "Step # 215  loss= 49.0336\n",
      "Step # 216  loss= 48.6811\n",
      "Step # 217  loss= 48.1574\n",
      "Step # 218  loss= 48.1535\n",
      "Step # 219  loss= 48.3179\n",
      "Step # 220  loss= 47.3495\n",
      "DAS model saved at iteration number  220  with cost =  47.3495\n",
      "Step # 221  loss= 47.2497\n",
      "Step # 222  loss= 47.6996\n",
      "Step # 223  loss= 46.5699\n",
      "Step # 224  loss= 46.5095\n",
      "Step # 225  loss= 45.7409\n",
      "Step # 226  loss= 45.9054\n",
      "Step # 227  loss= 46.2218\n",
      "Step # 228  loss= 45.7448\n",
      "Step # 229  loss= 44.8679\n",
      "Step # 230  loss= 44.7983\n",
      "Step # 231  loss= 45.2727\n",
      "Step # 232  loss= 45.1623\n",
      "Step # 233  loss= 44.4009\n",
      "Step # 234  loss= 44.5208\n",
      "Step # 235  loss= 43.8456\n",
      "Step # 236  loss= 44.132\n",
      "Step # 237  loss= 42.5806\n",
      "Step # 238  loss= 43.3465\n",
      "Step # 239  loss= 43.1113\n",
      "Step # 240  loss= 43.4243\n",
      "DAS model saved at iteration number  240  with cost =  43.4243\n",
      "Step # 241  loss= 42.4698\n",
      "Step # 242  loss= 41.2267\n",
      "Step # 243  loss= 42.5015\n",
      "Step # 244  loss= 42.6893\n",
      "Step # 245  loss= 41.6365\n",
      "Step # 246  loss= 41.0245\n",
      "Step # 247  loss= 41.5434\n",
      "Step # 248  loss= 42.0519\n",
      "Step # 249  loss= 40.576\n",
      "Step # 250  loss= 40.4756\n",
      "Step # 251  loss= 41.3456\n",
      "Step # 252  loss= 40.2193\n",
      "Step # 253  loss= 40.6252\n",
      "Step # 254  loss= 40.2234\n",
      "Step # 255  loss= 39.5218\n",
      "Step # 256  loss= 39.8877\n",
      "Step # 257  loss= 39.4322\n",
      "Step # 258  loss= 39.7831\n",
      "Step # 259  loss= 38.754\n",
      "Step # 260  loss= 39.2187\n",
      "DAS model saved at iteration number  260  with cost =  39.2187\n",
      "Step # 261  loss= 38.6199\n",
      "Step # 262  loss= 37.533\n",
      "Step # 263  loss= 37.9129\n",
      "Step # 264  loss= 38.6141\n",
      "Step # 265  loss= 38.3678\n",
      "Step # 266  loss= 39.0221\n",
      "Step # 267  loss= 37.5915\n",
      "Step # 268  loss= 37.8519\n",
      "Step # 269  loss= 37.7329\n",
      "Step # 270  loss= 37.3402\n",
      "Step # 271  loss= 37.7103\n",
      "Step # 272  loss= 37.3737\n",
      "Step # 273  loss= 36.1678\n",
      "Step # 274  loss= 36.4409\n",
      "Step # 275  loss= 36.4184\n",
      "Step # 276  loss= 36.431\n",
      "Step # 277  loss= 36.4466\n",
      "Step # 278  loss= 37.2536\n",
      "Step # 279  loss= 35.8377\n",
      "Step # 280  loss= 36.2758\n",
      "DAS model saved at iteration number  280  with cost =  36.2758\n",
      "Step # 281  loss= 36.149\n",
      "Step # 282  loss= 35.1997\n",
      "Step # 283  loss= 35.7828\n",
      "Step # 284  loss= 36.5203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step # 285  loss= 36.0191\n",
      "Step # 286  loss= 34.7683\n",
      "Step # 287  loss= 35.7239\n",
      "Step # 288  loss= 35.5106\n",
      "Step # 289  loss= 34.5272\n",
      "Step # 290  loss= 34.627\n",
      "Step # 291  loss= 35.0789\n",
      "Step # 292  loss= 34.3879\n",
      "Step # 293  loss= 33.8159\n",
      "Step # 294  loss= 34.2258\n",
      "Step # 295  loss= 33.4258\n",
      "Step # 296  loss= 34.4677\n",
      "Step # 297  loss= 33.5358\n",
      "Step # 298  loss= 34.243\n",
      "Step # 299  loss= 33.616\n",
      "Step # 300  loss= 33.5213\n",
      "DAS model saved at iteration number  300  with cost =  33.5213\n",
      "Step # 301  loss= 33.7629\n",
      "Step # 302  loss= 33.2803\n",
      "Step # 303  loss= 33.4837\n",
      "Step # 304  loss= 33.2983\n",
      "Step # 305  loss= 33.4349\n",
      "Step # 306  loss= 33.7973\n",
      "Step # 307  loss= 33.8824\n",
      "Step # 308  loss= 32.5734\n",
      "Step # 309  loss= 32.7787\n",
      "Step # 310  loss= 32.8504\n",
      "Step # 311  loss= 32.5141\n",
      "Step # 312  loss= 31.9862\n",
      "Step # 313  loss= 32.5661\n",
      "Step # 314  loss= 31.1083\n",
      "Step # 315  loss= 31.8342\n",
      "Step # 316  loss= 33.198\n",
      "Step # 317  loss= 32.5348\n",
      "Step # 318  loss= 32.259\n",
      "Step # 319  loss= 31.5473\n",
      "Step # 320  loss= 32.8877\n",
      "DAS model saved at iteration number  320  with cost =  32.8877\n",
      "Step # 321  loss= 32.0558\n",
      "Step # 322  loss= 32.0116\n",
      "Step # 323  loss= 31.9687\n",
      "Step # 324  loss= 31.4293\n",
      "Step # 325  loss= 32.4054\n",
      "Step # 326  loss= 30.7872\n",
      "Step # 327  loss= 30.9192\n",
      "Step # 328  loss= 30.1066\n",
      "Step # 329  loss= 31.2506\n",
      "Step # 330  loss= 31.687\n",
      "Step # 331  loss= 30.8626\n",
      "Step # 332  loss= 30.0635\n",
      "Step # 333  loss= 30.7479\n",
      "Step # 334  loss= 31.063\n",
      "Step # 335  loss= 32.0411\n",
      "Step # 336  loss= 31.1649\n",
      "Step # 337  loss= 31.1514\n",
      "Step # 338  loss= 30.1496\n",
      "Step # 339  loss= 30.9887\n",
      "Step # 340  loss= 29.4174\n",
      "DAS model saved at iteration number  340  with cost =  29.4174\n",
      "Step # 341  loss= 30.6027\n",
      "Step # 342  loss= 29.9803\n",
      "Step # 343  loss= 31.1004\n",
      "Step # 344  loss= 29.8423\n",
      "Step # 345  loss= 29.3689\n",
      "Step # 346  loss= 29.7316\n",
      "Step # 347  loss= 31.1204\n",
      "Step # 348  loss= 31.1501\n",
      "Step # 349  loss= 30.9019\n",
      "Step # 350  loss= 29.4242\n",
      "Step # 351  loss= 30.1995\n",
      "Step # 352  loss= 30.1712\n",
      "Step # 353  loss= 29.9567\n",
      "Step # 354  loss= 30.0373\n",
      "Step # 355  loss= 29.2266\n",
      "Step # 356  loss= 31.0234\n",
      "Step # 357  loss= 30.0647\n",
      "Step # 358  loss= 29.5607\n",
      "Step # 359  loss= 30.2857\n",
      "Step # 360  loss= 29.9794\n",
      "DAS model saved at iteration number  360  with cost =  29.9794\n",
      "Step # 361  loss= 30.3418\n",
      "Step # 362  loss= 28.9734\n",
      "Step # 363  loss= 29.0226\n",
      "Step # 364  loss= 30.0382\n",
      "Step # 365  loss= 28.9819\n",
      "Step # 366  loss= 29.4155\n",
      "Step # 367  loss= 29.724\n",
      "Step # 368  loss= 28.6406\n",
      "Step # 369  loss= 28.3212\n",
      "Step # 370  loss= 29.0045\n",
      "Step # 371  loss= 28.0359\n",
      "Step # 372  loss= 29.7666\n",
      "Step # 373  loss= 28.9416\n",
      "Step # 374  loss= 28.8074\n",
      "Step # 375  loss= 28.8189\n",
      "Step # 376  loss= 28.1358\n",
      "Step # 377  loss= 29.0554\n",
      "Step # 378  loss= 29.2721\n",
      "Step # 379  loss= 29.8519\n",
      "Step # 380  loss= 28.6757\n",
      "DAS model saved at iteration number  380  with cost =  28.6757\n",
      "Step # 381  loss= 28.8408\n",
      "Step # 382  loss= 30.2534\n",
      "Step # 383  loss= 28.3302\n",
      "Step # 384  loss= 28.4074\n",
      "Step # 385  loss= 29.6058\n",
      "Step # 386  loss= 29.7916\n",
      "Step # 387  loss= 27.568\n",
      "Step # 388  loss= 27.2102\n",
      "Step # 389  loss= 29.0554\n",
      "Step # 390  loss= 28.5123\n",
      "Step # 391  loss= 30.6271\n",
      "Step # 392  loss= 28.9225\n",
      "Step # 393  loss= 29.8034\n",
      "Step # 394  loss= 28.8317\n",
      "Step # 395  loss= 28.6315\n",
      "Step # 396  loss= 26.7355\n",
      "Step # 397  loss= 27.4057\n",
      "Step # 398  loss= 29.2508\n",
      "Step # 399  loss= 29.3694\n",
      "Step # 400  loss= 27.1389\n",
      "DAS model saved at iteration number  400  with cost =  27.1389\n",
      "Step # 401  loss= 28.2998\n",
      "Step # 402  loss= 29.8032\n",
      "Step # 403  loss= 27.7664\n",
      "Step # 404  loss= 29.3854\n",
      "Step # 405  loss= 29.0765\n",
      "Step # 406  loss= 28.1696\n",
      "Step # 407  loss= 29.9224\n",
      "Step # 408  loss= 28.497\n",
      "Step # 409  loss= 29.3065\n",
      "Step # 410  loss= 28.4624\n",
      "Step # 411  loss= 28.3338\n",
      "Step # 412  loss= 26.7606\n",
      "Step # 413  loss= 29.763\n",
      "Step # 414  loss= 28.4104\n",
      "Step # 415  loss= 27.9165\n",
      "Step # 416  loss= 27.8729\n",
      "Step # 417  loss= 28.7418\n",
      "Step # 418  loss= 28.4176\n",
      "Step # 419  loss= 28.175\n",
      "Step # 420  loss= 28.7747\n",
      "DAS model saved at iteration number  420  with cost =  28.7747\n",
      "Step # 421  loss= 29.6767\n",
      "Step # 422  loss= 29.8252\n",
      "Step # 423  loss= 27.2669\n",
      "Step # 424  loss= 28.7065\n",
      "Step # 425  loss= 27.7374\n",
      "Step # 426  loss= 28.5999\n",
      "Step # 427  loss= 27.4685\n",
      "Step # 428  loss= 26.8305\n",
      "Step # 429  loss= 27.7498\n",
      "Step # 430  loss= 29.6378\n",
      "Step # 431  loss= 27.9601\n",
      "Step # 432  loss= 28.968\n",
      "Step # 433  loss= 29.5468\n",
      "Step # 434  loss= 28.2297\n",
      "Step # 435  loss= 27.2283\n",
      "Step # 436  loss= 28.7771\n",
      "Step # 437  loss= 26.9508\n",
      "Step # 438  loss= 28.0924\n",
      "Step # 439  loss= 28.9791\n",
      "Step # 440  loss= 27.4007\n",
      "DAS model saved at iteration number  440  with cost =  27.4007\n",
      "Step # 441  loss= 25.282\n",
      "Step # 442  loss= 28.6415\n",
      "Step # 443  loss= 26.9223\n",
      "Step # 444  loss= 29.3793\n",
      "Step # 445  loss= 28.547\n",
      "Step # 446  loss= 29.1575\n",
      "Step # 447  loss= 28.0343\n",
      "Step # 448  loss= 27.6973\n",
      "Step # 449  loss= 27.2404\n",
      "Step # 450  loss= 24.3911\n",
      "Step # 451  loss= 28.2863\n",
      "Step # 452  loss= 27.7659\n",
      "Step # 453  loss= 27.4027\n",
      "Step # 454  loss= 29.29\n",
      "Step # 455  loss= 27.7347\n",
      "Step # 456  loss= 26.54\n",
      "Step # 457  loss= 28.6456\n",
      "Step # 458  loss= 26.418\n",
      "Step # 459  loss= 28.0329\n",
      "Step # 460  loss= 25.8675\n",
      "DAS model saved at iteration number  460  with cost =  25.8675\n",
      "Step # 461  loss= 29.8539\n",
      "Step # 462  loss= 27.4376\n",
      "Step # 463  loss= 28.4079\n",
      "Step # 464  loss= 28.9902\n",
      "Step # 465  loss= 27.1002\n",
      "Step # 466  loss= 27.9377\n",
      "Step # 467  loss= 28.7494\n",
      "Step # 468  loss= 27.5857\n",
      "Step # 469  loss= 25.8385\n",
      "Step # 470  loss= 26.9362\n",
      "Step # 471  loss= 28.1749\n",
      "Step # 472  loss= 26.9314\n",
      "Step # 473  loss= 29.195\n",
      "Step # 474  loss= 26.6896\n",
      "Step # 475  loss= 27.1886\n",
      "Step # 476  loss= 30.4989\n",
      "Step # 477  loss= 25.4698\n",
      "Step # 478  loss= 29.207\n",
      "Step # 479  loss= 28.1049\n",
      "Step # 480  loss= 27.998\n",
      "DAS model saved at iteration number  480  with cost =  27.998\n",
      "Step # 481  loss= 29.3682\n",
      "Step # 482  loss= 27.3367\n",
      "Step # 483  loss= 27.7161\n",
      "Step # 484  loss= 27.9158\n",
      "Step # 485  loss= 28.7167\n",
      "Step # 486  loss= 27.891\n",
      "Step # 487  loss= 26.0891\n",
      "Step # 488  loss= 30.3476\n",
      "Step # 489  loss= 28.319\n",
      "Step # 490  loss= 28.1905\n",
      "Step # 491  loss= 26.0818\n",
      "Step # 492  loss= 30.0704\n",
      "Step # 493  loss= 27.3399\n",
      "Step # 494  loss= 26.9782\n",
      "Step # 495  loss= 27.7608\n",
      "Step # 496  loss= 27.4332\n",
      "Step # 497  loss= 28.5079\n",
      "Step # 498  loss= 24.4743\n",
      "Step # 499  loss= 28.4458\n",
      "Step # 500  loss= 25.1823\n",
      "DAS model saved at iteration number  500  with cost =  25.1823\n",
      "Step # 501  loss= 27.5572\n",
      "Step # 502  loss= 26.4771\n",
      "Step # 503  loss= 24.6341\n",
      "Step # 504  loss= 30.1479\n",
      "Step # 505  loss= 27.0654\n",
      "Step # 506  loss= 27.7035\n",
      "Step # 507  loss= 28.4972\n",
      "Step # 508  loss= 26.634\n",
      "Step # 509  loss= 27.0378\n",
      "Step # 510  loss= 26.8005\n",
      "Step # 511  loss= 27.022\n",
      "Step # 512  loss= 27.2463\n",
      "Step # 513  loss= 26.8373\n",
      "Step # 514  loss= 30.0615\n",
      "Step # 515  loss= 27.7354\n",
      "Step # 516  loss= 28.3892\n",
      "Step # 517  loss= 27.8708\n",
      "Step # 518  loss= 26.5562\n",
      "Step # 519  loss= 29.004\n",
      "Step # 520  loss= 26.3208\n",
      "DAS model saved at iteration number  520  with cost =  26.3208\n",
      "Step # 521  loss= 27.6458\n",
      "Step # 522  loss= 28.2567\n",
      "Step # 523  loss= 27.1718\n",
      "Step # 524  loss= 27.7279\n",
      "Step # 525  loss= 27.8129\n",
      "Step # 526  loss= 28.6582\n",
      "Step # 527  loss= 25.7234\n",
      "Step # 528  loss= 26.8464\n",
      "Step # 529  loss= 27.5331\n",
      "Step # 530  loss= 29.2612\n",
      "Step # 531  loss= 27.7868\n",
      "Step # 532  loss= 28.3453\n",
      "Step # 533  loss= 28.0061\n",
      "Step # 534  loss= 28.4849\n",
      "Step # 535  loss= 29.752\n",
      "Step # 536  loss= 26.579\n",
      "Step # 537  loss= 27.193\n",
      "Step # 538  loss= 29.0711\n",
      "Step # 539  loss= 24.7725\n",
      "Step # 540  loss= 26.5377\n",
      "DAS model saved at iteration number  540  with cost =  26.5377\n",
      "Step # 541  loss= 27.9562\n",
      "Step # 542  loss= 27.4853\n",
      "Step # 543  loss= 26.8149\n",
      "Step # 544  loss= 27.8357\n",
      "Step # 545  loss= 29.5774\n",
      "Step # 546  loss= 27.6229\n",
      "Step # 547  loss= 29.0414\n",
      "Step # 548  loss= 28.5747\n",
      "Step # 549  loss= 29.5404\n",
      "Step # 550  loss= 29.7431\n",
      "Step # 551  loss= 25.7285\n",
      "Step # 552  loss= 24.6337\n",
      "Step # 553  loss= 27.8403\n",
      "Step # 554  loss= 27.1832\n",
      "Step # 555  loss= 27.1216\n",
      "Step # 556  loss= 29.0944\n",
      "Step # 557  loss= 25.7686\n",
      "Step # 558  loss= 25.5013\n",
      "Step # 559  loss= 28.5132\n",
      "Step # 560  loss= 27.3911\n",
      "DAS model saved at iteration number  560  with cost =  27.3911\n",
      "Step # 561  loss= 26.7309\n",
      "Step # 562  loss= 29.3804\n",
      "Step # 563  loss= 28.8041\n",
      "Step # 564  loss= 24.8983\n",
      "Step # 565  loss= 28.4201\n",
      "Step # 566  loss= 27.3131\n",
      "Step # 567  loss= 27.7199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step # 568  loss= 29.4241\n",
      "Step # 569  loss= 26.958\n",
      "Step # 570  loss= 29.6225\n",
      "Step # 571  loss= 28.8206\n",
      "Step # 572  loss= 26.6519\n",
      "Step # 573  loss= 27.454\n",
      "Step # 574  loss= 27.4336\n",
      "Step # 575  loss= 28.6741\n",
      "Step # 576  loss= 28.7398\n",
      "Step # 577  loss= 28.0965\n",
      "Step # 578  loss= 25.0969\n",
      "Step # 579  loss= 27.1277\n",
      "Step # 580  loss= 26.4178\n",
      "DAS model saved at iteration number  580  with cost =  26.4178\n",
      "Step # 581  loss= 28.0311\n",
      "Step # 582  loss= 27.8594\n",
      "Step # 583  loss= 24.9138\n",
      "Step # 584  loss= 27.6105\n",
      "Step # 585  loss= 27.1619\n",
      "Step # 586  loss= 24.9944\n",
      "Step # 587  loss= 27.5943\n",
      "Step # 588  loss= 27.862\n",
      "Step # 589  loss= 27.998\n",
      "Step # 590  loss= 29.102\n",
      "Step # 591  loss= 29.4088\n",
      "Step # 592  loss= 28.8716\n",
      "Step # 593  loss= 27.879\n",
      "Step # 594  loss= 27.8882\n",
      "Step # 595  loss= 28.2256\n",
      "Step # 596  loss= 27.4835\n",
      "Step # 597  loss= 25.8809\n",
      "Step # 598  loss= 29.8995\n",
      "Step # 599  loss= 28.0197\n",
      "Step # 600  loss= 28.499\n",
      "DAS model saved at iteration number  600  with cost =  28.499\n",
      "Step # 601  loss= 26.197\n",
      "Step # 602  loss= 29.1672\n",
      "Step # 603  loss= 23.9517\n",
      "Step # 604  loss= 27.853\n",
      "Step # 605  loss= 29.8872\n",
      "Step # 606  loss= 29.1788\n",
      "Step # 607  loss= 25.4622\n",
      "Step # 608  loss= 28.5306\n",
      "Step # 609  loss= 28.0522\n",
      "Step # 610  loss= 26.6165\n",
      "Step # 611  loss= 28.063\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-98a0b1ffb159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Step #'\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' loss='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anthony/das/models/adapt.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_mix, X_in, learning_rate, step, ind_train)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mind_train\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                         \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_mix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_non_mix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                         \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_mix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_non_mix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mind_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_iterations = 1000\n",
    "\n",
    "#initialize the model\n",
    "model.sess.run(init)\n",
    "\n",
    "for i in range(nb_iterations):\n",
    "    X_in, X_mix, Ind = mixed_data.get_batch(batch_size)\n",
    "    c = model.train(X_mix, X_in, learning_rate, i)\n",
    "    print 'Step #'  ,i,' loss=', c \n",
    "\n",
    "    if i%20 == 0: #cost_valid < cost_valid_min:\n",
    "        print 'DAS model saved at iteration number ', i,' with cost = ', c \n",
    "        model.save(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
